{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd525fbf-1987-4e24-9a43-af57e3d8257e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Tarrant precincts: https://www.tarrantcountytx.gov/en/elections/interactive-maps/commissioner-precinct-maps.html\n",
    "- Texas VTDS: https://data.capitol.texas.gov/dataset/vtds/resource/906f47e4-4e39-4156-b1bd-4969be0b2780\n",
    "- Texas Elections: https://data.capitol.texas.gov/topic/elections\n",
    "- ACS: https://www.census.gov/programs-surveys/acs/data.html\n",
    "- Blockgroup shapefiles: https://www2.census.gov/geo/tiger/TIGER2023/BG/\n",
    "- Census Python: https://pypi.org/project/census/\n",
    "- CRS: https://epsg.io/3085 & https://epsg.io/4269\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdbf0361-5815-406a-95d5-eb723319764e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "try:\n",
    "    %reload_ext autotime\n",
    "except:\n",
    "    %pip install -U ipython-autotime ipywidgets codetiming pandas geopandas matplotlib Census us\n",
    "    dbutils.library.restartPython()\n",
    "    clear_output()\n",
    "    dbutils.notebook.exit('Rerun to use newly installed/updated packages')\n",
    "\n",
    "import warnings, os, pathlib, dataclasses, codetiming, requests, zipfile, us, census, numpy as np, pandas as pd, geopandas as gpd, matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = None\n",
    "####################### helper functions #######################\n",
    "\n",
    "def get_size(path):\n",
    "    os.system(f'du -h {path}')\n",
    "\n",
    "def rm(path, root=False):\n",
    "    path = pathlib.Path(path)\n",
    "    if path.is_file():\n",
    "        path.unlink()\n",
    "    elif path.is_dir():\n",
    "        if root:\n",
    "            shutil.rmtree(path)\n",
    "        else:\n",
    "            for p in path.iterdir():\n",
    "                rm(p, True)\n",
    "    return path\n",
    "\n",
    "def mkdir(path):\n",
    "    path = pathlib.Path(path)\n",
    "    (path if path.suffix == '' else path.parent).mkdir(parents=True, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def reset(path):\n",
    "    rm(path)\n",
    "    mkdir(path)\n",
    "    return path\n",
    "\n",
    "def fetch(path, url, overwrite=False):\n",
    "    path = pathlib.Path(path)\n",
    "    if overwrite or not path.exists():\n",
    "        reset(path)\n",
    "        response = requests.get(url)\n",
    "        print(f'fetching {url} to {path}')\n",
    "        with open(path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        if zipfile.is_zipfile(path):\n",
    "            with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(path.parent)\n",
    "    return path\n",
    "\n",
    "def dump(path, obj):\n",
    "    obj = obj.prep()\n",
    "    obj.to_parquet(reset(path))\n",
    "    return obj\n",
    "\n",
    "def load(path):\n",
    "    return gpd.read_parquet(path)\n",
    "\n",
    "def disp(X, max_rows=3, sort=False):\n",
    "    \"\"\"convenient display method\"\"\"\n",
    "    print(X.shape)\n",
    "    X = (X.sort_index(axis=1) if sort else X).reset_index()\n",
    "    Y = pd.DataFrame({'dtype':X.dtypes.astype('string'), 'missing_pct':X.isnull().mean()*100}).T.rename_axis('column').reset_index().prep(case='')\n",
    "    display(Y)\n",
    "    display(X.head(max_rows))\n",
    "\n",
    "def to_numeric(df, case='lower', downcast='integer', errors='ignore', category=False, **kwargs):\n",
    "    \"\"\"convert to numeric dtypes if possible\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        case = case if case in dir(pd.Series().str) else 'strip'\n",
    "        return (\n",
    "            df\n",
    "            .apply(lambda s: getattr(s.astype('string').str.strip().str,case)() if s.dtype in ['object','string'] else s)  # prep strings\n",
    "            .apply(lambda s: s if pd.api.types.is_datetime64_any_dtype(s) or s.dtype in ['geometry'] else pd.to_numeric(s, downcast=downcast, errors=errors, **kwargs))  # convert to numeric if possible\n",
    "            .convert_dtypes()  # convert to new nullable dtypes\n",
    "            .apply(lambda s: s.astype('Int64') if pd.api.types.is_integer_dtype(s) else s.astype('category') if s.dtype in ['object','string'] and category else s)\n",
    "        )\n",
    "\n",
    "def prep(df, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        h = lambda x: x.to_numeric(**kwargs).rename(columns=lambda s: s.lower().strip() if isinstance(s, str) else s)\n",
    "        idx = h(df[[]].reset_index())  # drop columns, reset_index to move index to columns, then apply g\n",
    "        return h(df).reset_index(drop=True).set_index(pd.MultiIndex.from_frame(idx))  # set idx back to df's index\n",
    "\n",
    "def get_area(df):\n",
    "    return df.assign(area=df.geometry.to_crs('EPSG:3085').area)\n",
    "\n",
    "def get_mlt(df, grp, col):\n",
    "    return df.groupby(grp)[[col]].transform(lambda x: x/x.sum()).values\n",
    "\n",
    "for fcn in [disp, to_numeric, prep, get_area, get_mlt]:\n",
    "    \"\"\"monkey-patch helpers into (Geo)Pandas DataFrame so we can use df.method syntax\"\"\"\n",
    "    setattr(pd.DataFrame, fcn.__name__, fcn)\n",
    "    setattr(gpd.GeoDataFrame, fcn.__name__, fcn)\n",
    "\n",
    "####################### real code #######################\n",
    "\n",
    "suf = lambda s, x='geoid': type(x)(f'{k}_{s}' for k in x) if isinstance(x,(list,tuple,set)) else f'{x}_{s}'\n",
    "read_geo = lambda s, **kwargs: gpd.read_file(s, **kwargs).prep().to_crs('EPSG:4269')\n",
    "intersect = lambda X, Y, **kwargs: gpd.overlay(X, Y, keep_geom_type=True, **kwargs)\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Redistricting():\n",
    "    years: tuple = (2020,2021,2022,2023)\n",
    "    current: int = 2024\n",
    "    state: any = us.states.TX\n",
    "    districts: tuple = ('precinct','congress','senate','house','commish','jp','education')\n",
    "    offices: tuple = ('president','u.s. sen','governor','lt. governor','attorney gen')\n",
    "    api_key: str = '5640e76608e24d8d6cc35b96ce35028445957cb5'\n",
    "    acs: dict = (('B25034_010E','structures1940'),)\n",
    "    overwrite: set = None\n",
    "\n",
    "\n",
    "    #Allows self['attr'] and self.attr syntax\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "    def __delitem__(self, key):\n",
    "        if key in self:\n",
    "            delattr(self, key)\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.root = pathlib.Path(f'/Volumes/aiml/scook/scook_files/redistricting/{self.state.abbr}')\n",
    "        self.prc = self.root/f'processed'\n",
    "        self.acs = dict(self.acs)\n",
    "        self.districts = list(self.districts)\n",
    "        self.overwrite = set() if self.overwrite is None else set(self.overwrite)\n",
    "\n",
    "\n",
    "    def get(self, fcn, nm, prereq=[], **kwargs):\n",
    "        dst = self.prc/f\"{nm.split('_')[0]}/{nm}.parquet\"\n",
    "        if nm in self.overwrite:\n",
    "            del self[nm]\n",
    "            reset(dst)\n",
    "            self.overwrite.remove(nm)\n",
    "        if not nm in self:\n",
    "            if dst.exists():\n",
    "                self[nm] = load(dst)\n",
    "            else:\n",
    "                [f() for f in prereq]\n",
    "                print(f'creating {dst}')\n",
    "                with codetiming.Timer():\n",
    "                    self[nm] = dump(dst, fcn(**kwargs))\n",
    "        return self[nm]\n",
    "\n",
    "\n",
    "    def get_blkgrps_yr(self, yr):\n",
    "        def fcn():\n",
    "            dst = self.root/f'data/blkgrps/{yr}/blkgrps_{yr}.zip'\n",
    "            url = f'https://www2.census.gov/geo/tiger/TIGER{yr}/BG/tl_{yr}_{self.state.fips}_bg.zip'\n",
    "            geo = read_geo(fetch(dst, url), columns=['GEOID','geometry']).set_index('geoid')\n",
    "\n",
    "            dst = self.root/f'data/cvap/{yr}/cvap_{yr}.zip'\n",
    "            url = f'https://www2.census.gov/programs-surveys/decennial/rdo/datasets/{yr}/{yr}-cvap/CVAP_{yr-4}-{yr}_ACS_csv_files.zip'\n",
    "            cvap = (\n",
    "                pd.read_csv(fetch(dst,url).parent/'BlockGr.csv', encoding='latin1')\n",
    "                .prep()\n",
    "                .assign(geoid=lambda X: X['geoid'].str[-12:])\n",
    "                .pivot_table(index='geoid', columns='lntitle', values=['cit_est','cvap_est'])\n",
    "                .fillna(0)\n",
    "                .prep()\n",
    "                .rename_axis('geoid')\n",
    "            )\n",
    "            cvap.columns = [k[:-3]+v for k,v in cvap.columns]\n",
    "\n",
    "            # activate if Census API is down to skip code below\n",
    "            return geo.join(cvap).reset_index().rename(columns=lambda x: x if x=='geometry' else suf(yr,x))\n",
    "\n",
    "            g = lambda s, x: x.astype(str).str.rjust(s,'0')\n",
    "            acs = (\n",
    "                pd.DataFrame(census.Census(self.api_key).acs5.state_county_blockgroup([*self.acs.keys()], self.state.fips, '*', '*', year=yr))\n",
    "                .assign(geoid=lambda X: g(2,X['state']) + g(3,X['county']) + g(6,X['tract']) + g(1,X['block group']))\n",
    "                .set_index('geoid')\n",
    "                [[*self.acs.keys()]]\n",
    "                .rename(columns=self.acs)\n",
    "                .prep()\n",
    "            )\n",
    "            print('acs')\n",
    "            return geo.join(acs).join(cvap).reset_index().rename(columns=lambda x: x if x=='geometry' else suf(yr,x))\n",
    "        return self.get(fcn, f'blkgrps_{yr}')\n",
    "\n",
    "\n",
    "    def get_blkgrps(self):\n",
    "        self.blkgrps = {yr: self.get_blkgrps_yr(yr) for yr in self.years}\n",
    "        return self.blkgrps\n",
    "\n",
    "\n",
    "    def get_vtds(self):\n",
    "        def fcn():\n",
    "            yr = self.current\n",
    "            dst = self.root/f'data/vtds/{yr}/vtds_{yr}.zip'\n",
    "            url = f'https://data.capitol.texas.gov/dataset/4d8298d0-d176-4c19-b174-42837027b73e/resource/906f47e4-4e39-4156-b1bd-4969be0b2780/download/vtds_{yr}pg.zip'\n",
    "            geo = read_geo(fetch(dst, url), columns=['VTDKEY'])\n",
    "\n",
    "            # get district info from Tarrant County shapefile released by FOIA to Cook\n",
    "            tarrant = read_geo(self.root/f'precincts/{yr}/precincts_{yr}_tarrant')\n",
    "            tarrant = intersect(tarrant, geo).get_area().sort_values('area').groupby('vtdkey')[self.districts].last()\n",
    "\n",
    "            dst = self.root/f'data/elections/{yr}/elections_{yr}.zip'\n",
    "            url = f'https://data.capitol.texas.gov/dataset/35b16aee-0bb0-4866-b1ec-859f1f044241/resource/e1cd6332-6a7a-4c78-ad2a-852268f6c7a2/download/{yr}-general-vtds-election-data.zip'\n",
    "            elections = pd.concat(\n",
    "                    pd.read_csv(fetch(dst,url).parent/f'{elec}_General_Election_Returns.csv').prep()\n",
    "                    .assign(\n",
    "                        vtdkey=lambda X: X['vtdkeyvalue'],\n",
    "                        office=lambda X: X['office'].str.replace(\"_\",\" \").str.replace(\".\",\"\").str.replace(\"'\",\"\"),\n",
    "                        name  =lambda X: X['name'  ].str.replace(\"_\",\" \").str.replace(\".\",\"\").str.replace(\"'\",\"\"),\n",
    "                        candidate=lambda X: str(elec)+'_'+X['office']+'_'+X['party']+'_'+X['name']\n",
    "                    )\n",
    "                    .query(f'office in {self.offices}')\n",
    "                    for elec in self.years if elec%2==0\n",
    "                ).pivot_table(index=['vtdkey','county'], columns='candidate', values='votes').fillna(0).prep()\n",
    "            return geo.set_index('vtdkey').join(tarrant).join(elections).reset_index()\n",
    "        return self.get(fcn, f'vtds')\n",
    "\n",
    "\n",
    "    def get_pieces_geo(self):\n",
    "        def fcn():\n",
    "            df = None\n",
    "            for yr, blkgrp in self.get_blkgrps().items():\n",
    "                print(yr)\n",
    "                B = blkgrp[['geometry',suf(yr)]]\n",
    "                df = B if df is None else intersect(df, B)\n",
    "            print('vtds')\n",
    "            V = self.get_vtds()[['geometry','vtdkey']]\n",
    "            df = intersect(V, df).get_area()\n",
    "            print('done')\n",
    "            return df\n",
    "        return self.get(fcn, f'pieces_geo', [self.get_blkgrps, self.get_vtds])\n",
    "\n",
    "\n",
    "    def get_pieces(self):\n",
    "        def fcn():\n",
    "            df = self.get_pieces_geo().merge(self.get_vtds().drop(columns='geometry'), on='vtdkey')\n",
    "            for yr, blkgrp in self.get_blkgrps().items():\n",
    "                df = df.merge(blkgrp.drop(columns='geometry'), on=suf(yr))\n",
    "                # get population columns for this year & apportion to pieces based on area\n",
    "                col = df.filter(like=f'_{yr}').columns.drop(suf(yr))\n",
    "                df[col] *= df.get_mlt(suf(yr), 'area')\n",
    "                # get votes columns for this year & apportion to pieces based on cvap_total\n",
    "                col = df.filter(like=f'{yr}_').columns\n",
    "                df[col] *= df.get_mlt(suf(yr), suf(yr,'cvap_total'))\n",
    "            return df\n",
    "        return self.get(fcn, f'pieces', [self.get_blkgrps, self.get_vtds, self.get_pieces_geo])\n",
    "\n",
    "\n",
    "    def dissolve(self, by='vtdkey'):\n",
    "        # combine pieces based on \"by\"\n",
    "        def fcn():\n",
    "            df = self.get_pieces()\n",
    "            aggfunc = {x:lambda x: pd.NA if x.isnull().all() else x.mode().iloc[0] for x in self.districts} # most frequent districts\n",
    "            aggfun |= {x:'sum' for x in df.loc[:,self.districts[-1]:].columns[1:]} # sum populations & votes\n",
    "            return df.dissolve(by=suf(by) if str(by).isdigit() else by, aggfunc=aggfunc)\n",
    "        return self.get(fcn, f'dissolve_{by}', [self.get_pieces])\n",
    "\n",
    "years = np.arange(2014,2024)\n",
    "self = Redistricting(\n",
    "    years=years,\n",
    "    offices = [\n",
    "        'president','us sen','governor','lt governor','attorney gen',\n",
    "        # 'comptroller','land comm','ag comm',\n",
    "        # 'rr comm 1','rr comm 2','rr comm 3',\n",
    "        # 'sup ct chief','sup ct 1','sup ct 2','sup ct 3','sup ct 4','sup ct 5','sup ct 6','sup ct 7','sup ct 8','sup ct 9',\n",
    "        # 'cca pres judge','cca1','cca2','cca3','cca4','cca5','cca6','cca7','cca8','cca9',\n",
    "    ],\n",
    "    overwrite=set({\n",
    "        *{f'blkgrps_{yr}' for yr in years},\n",
    "        'vtds',\n",
    "        'pieces_geo',\n",
    "        'pieces',\n",
    "        'dissolve_vtdkey',\n",
    "        *{f'dissolve_{suf(yr)}' for yr in years},\n",
    "    }),\n",
    ")\n",
    "self.dissolve('vtdkey')\n",
    "for yr in self.years:\n",
    "    self.dissolve(yr)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "redistricting_wrangler",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
