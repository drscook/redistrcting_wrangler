{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd525fbf-1987-4e24-9a43-af57e3d8257e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Tarrant precincts: https://www.tarrantcountytx.gov/en/elections/interactive-maps/commissioner-precinct-maps.html\n",
    "- Texas VTDS: https://data.capitol.texas.gov/dataset/vtds/resource/906f47e4-4e39-4156-b1bd-4969be0b2780\n",
    "- Texas Elections: https://data.capitol.texas.gov/topic/elections\n",
    "- ACS: https://www.census.gov/programs-surveys/acs/data.html\n",
    "- Blockgroup shapefiles: https://www2.census.gov/geo/tiger/TIGER2023/BG/\n",
    "- Census Python: https://pypi.org/project/census/\n",
    "- CRS: https://epsg.io/3085 & https://epsg.io/4269\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d89c4c69-73de-49a1-9e90-24502d5fd32f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display\n",
    "try:\n",
    "    %reload_ext autotime\n",
    "except:\n",
    "    %pip install -U ipython-autotime ipywidgets codetiming numpy pandas geopandas matplotlib Census us\n",
    "    dbutils.library.restartPython()\n",
    "    clear_output()\n",
    "    dbutils.notebook.exit('Rerun to use newly installed/updated packages')\n",
    "\n",
    "import warnings, os, pathlib, dataclasses, codetiming, requests, zipfile, us, census, numpy as np, pandas as pd, geopandas as gpd, pyarrow.parquet as pq, matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = None\n",
    "warnings.filterwarnings(category=FutureWarning, action='ignore')\n",
    "################################################################\n",
    "####################### helper functions #######################\n",
    "################################################################\n",
    "\n",
    "####################### dataframe extensions #######################\n",
    "def disp(X, max_rows=3, sort=False):\n",
    "    \"\"\"convenient display method\"\"\"\n",
    "    print(type(X), X.shape)\n",
    "    X = (X.sort_index(axis=1) if sort else X).reset_index()\n",
    "    Y = pd.DataFrame({'dtype':X.dtypes.astype('string'), 'missing_pct':X.isnull().mean()*100}).T.rename_axis('column').reset_index().prep(case='')\n",
    "    print(X.shape)\n",
    "    display(Y)\n",
    "    display(X.head(max_rows))\n",
    "\n",
    "def to_numeric(df, case='lower', downcast='integer', errors='ignore', category=False, **kwargs):\n",
    "    \"\"\"convert to numeric dtypes if possible\"\"\"\n",
    "    case = case if case in dir(pd.Series().str) else 'strip'\n",
    "    return (\n",
    "        df\n",
    "        .apply(lambda s: getattr(s.astype('string').str.strip().str,case)() if s.dtype in ['object','string'] else s)  # prep strings\n",
    "        .apply(lambda s: s if pd.api.types.is_datetime64_any_dtype(s) or s.dtype in ['category','geometry'] else pd.to_numeric(s, downcast=downcast, errors=errors, **kwargs))  # convert to numeric if possible\n",
    "        .convert_dtypes()  # convert to new nullable dtypes\n",
    "        .apply(lambda s: s.astype('Int64') if pd.api.types.is_integer_dtype(s) else s.astype('category') if s.dtype in ['object','string'] and category else s)\n",
    "    )\n",
    "\n",
    "def prep(df, **kwargs):\n",
    "    h = lambda x: x.to_numeric(**kwargs).rename(columns=lambda s: s.lower().strip() if isinstance(s, str) else s)\n",
    "    idx = h(df[[]].reset_index())  # drop columns, reset_index to move index to columns, then apply g\n",
    "    df = h(df).reset_index(drop=True).set_index(pd.MultiIndex.from_frame(idx))  # set idx back to df's index\n",
    "    return df.to_crs('EPSG:4269') if isinstance(df, gpd.GeoDataFrame) else df\n",
    "\n",
    "def buffer(df, distance=0, **kwargs):\n",
    "    return df.assign(geometry=df.geometry.buffer(distance, **kwargs))\n",
    "\n",
    "def simplify(df, tolerance=0, **kwargs):\n",
    "    return df.assign(geometry=df.geometry.simplify(tolerance, **kwargs))\n",
    "\n",
    "def overlay(df, other, **kwargs):\n",
    "    return gpd.overlay(df, other.to_crs(df.crs), keep_geom_type=True, **kwargs)#.buffer(0).simplify(0)\n",
    "\n",
    "def refine(df, other, **kwargs):\n",
    "    return pd.concat(df.overlay(other, how=how, **kwargs) for how in ['intersection', 'difference'])#.buffer(0).simplify(0)\n",
    "\n",
    "def get_area(df):\n",
    "    return df.assign(area=df.geometry.to_crs('EPSG:3085').area)\n",
    "\n",
    "def get_proportion(df, grp, col):\n",
    "    return df.groupby(grp)[[col]].transform(lambda x: x/x.sum()).values\n",
    "\n",
    "for fcn in [disp, to_numeric, prep, simplify, buffer, overlay, refine, get_area, get_proportion]:\n",
    "    \"\"\"monkey-patch helpers into (Geo)Pandas DataFrame so we can use df.method syntax\"\"\"\n",
    "    setattr(pd.DataFrame, fcn.__name__, fcn)\n",
    "    setattr(gpd.GeoDataFrame, fcn.__name__, fcn)\n",
    "\n",
    "####################### file i/o #######################\n",
    "\n",
    "def get_size(path):\n",
    "    os.system(f'du -h {path}')\n",
    "\n",
    "def rm(path, root=False):\n",
    "    path = pathlib.Path(path)\n",
    "    if path.is_file():\n",
    "        path.unlink()\n",
    "    elif path.is_dir():\n",
    "        if root:\n",
    "            shutil.rmtree(path)\n",
    "        else:\n",
    "            for p in path.iterdir():\n",
    "                rm(p, True)\n",
    "    return path\n",
    "\n",
    "def mkdir(path):\n",
    "    path = pathlib.Path(path)\n",
    "    (path if path.suffix == '' else path.parent).mkdir(parents=True, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def reset(path):\n",
    "    rm(path)\n",
    "    mkdir(path)\n",
    "    return path\n",
    "\n",
    "def dump(path, obj, **kwargs):\n",
    "    obj.to_parquet(reset(path), **kwargs)\n",
    "\n",
    "def load(path, coerce=False, **kwargs):\n",
    "    path = pathlib.Path(path)\n",
    "    if path.suffix == '.parquet':\n",
    "        if 'geometry' in pq.ParquetFile(path).schema.names:\n",
    "            obj = gpd.read_parquet(path, **kwargs)\n",
    "        else:\n",
    "            obj = pd.read_parquet(path, **kwargs)\n",
    "    elif path.suffix == '.csv':\n",
    "        obj = pd.read_csv(path, **kwargs)\n",
    "    else:\n",
    "        obj = gpd.read_file(path, **kwargs)\n",
    "    return obj.prep()\n",
    "\n",
    "#########################################################\n",
    "####################### real code #######################\n",
    "#########################################################\n",
    "\n",
    "def suf(s, x='blkgrp'):\n",
    "    return [f'{k}_{s}' for k in x] if isinstance(x,(list,tuple,set)) else f'{x}_{s}'\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Data():\n",
    "    years: tuple = (2020,2021,2022,2023)\n",
    "    current: int = 2024\n",
    "    state: any = us.states.TX\n",
    "    api_key: str = '5640e76608e24d8d6cc35b96ce35028445957cb5'\n",
    "    overwrite: set = None\n",
    "\n",
    "    #Allows self['attr'] and self.attr syntax\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "    def __delitem__(self, key):\n",
    "        if key in self:\n",
    "            delattr(self, key)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.root = pathlib.Path(f'/Volumes/aiml/scook/scook_files/redistricting/{self.state.abbr}')\n",
    "        self.overwrite = set() if self.overwrite is None else set(self.overwrite)\n",
    "        for nm in self.overwrite.intersection({'blkgrps', 'acs', 'cvap', 'dissolved_blkgrp'}):\n",
    "            self.overwrite |= {f'{nm}_{yr}' for yr in years}\n",
    "            self.overwrite -= {nm}\n",
    "\n",
    "    def dst(self, nm, suf):\n",
    "        return self.root/f\"data/{nm.replace('_','/')}/{nm}.{suf.strip('.')}\"\n",
    "    \n",
    "    def fetch(self, nm, url=None, unzip=True, **kwargs):\n",
    "        dst = self.dst(nm, 'zip')\n",
    "        if url and not dst.exists():\n",
    "            print(f'fetching {url} to {dst}')\n",
    "            reset(dst)\n",
    "            response = requests.get(url)\n",
    "            with open(dst, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            if unzip and zipfile.is_zipfile(dst):\n",
    "                with zipfile.ZipFile(dst, 'r') as file:\n",
    "                    file.extractall(dst.parent)\n",
    "        return dst\n",
    "\n",
    "    def get(self, nm, fcn=None, prereq=[], coerce=False, **kwargs):\n",
    "        dst = self.dst(nm, 'parquet')\n",
    "        if nm in self.overwrite:\n",
    "            del self[nm]\n",
    "            reset(dst)\n",
    "            self.overwrite -= {nm}\n",
    "        if not nm in self:\n",
    "            if dst.exists():\n",
    "                self[nm] = load(dst)\n",
    "            else:\n",
    "                [f() for f in prereq]\n",
    "                with codetiming.Timer():\n",
    "                    print(f'creating {dst}')\n",
    "                    if fcn:\n",
    "                        self[nm] = fcn(**kwargs).prep()\n",
    "                    else:\n",
    "                        src = self.fetch(nm, unzip=False, **kwargs)\n",
    "                        if src.exists():\n",
    "                            self[nm] = load(src)\n",
    "                        elif coerce:\n",
    "                            print(f'cannot create {nm} - returning empty GeoDataFrame')\n",
    "                            self[nm] = gpd.GeoDataFrame(columns=['geometry'], crs='EPSG:4269')\n",
    "                    dump(dst, self[nm])\n",
    "        return self[nm]\n",
    "\n",
    "    def run_years(self, nm, fcn):\n",
    "        return [[yr, self.get(f'{nm}_{yr}', fcn, yr=yr)] for yr in self.years]\n",
    "\n",
    "    def get_elections(self):\n",
    "        def fcn():\n",
    "            src = self.fetch('elections', url=f'https://data.capitol.texas.gov/dataset/35b16aee-0bb0-4866-b1ec-859f1f044241/resource/e1cd6332-6a7a-4c78-ad2a-852268f6c7a2/download/{self.current}-general-vtds-election-data.zip')\n",
    "            df = pd.concat(load(fn).assign(year=fn.stem[:4]) for fn in src.parent.iterdir() if 'General_Election_Returns' in fn.stem and 'City' not in fn.stem)\n",
    "            for k in ['office','name']:\n",
    "                df[k] = df[k].str.replace('_',' ').str.replace('.', '')\n",
    "            return df.rename(columns={'vtdkeyvalue':'vtdkey'})\n",
    "        return self.get('elections', fcn)\n",
    "\n",
    "    def get_blkgrps(self):\n",
    "        return [[yr, self.get(f'blkgrps_{yr}', url=f'https://www2.census.gov/geo/tiger/TIGER{yr}/BG/tl_{yr}_{self.state.fips}_bg.zip')] for yr in self.years]\n",
    "    \n",
    "    # def get_blkgrps(self):\n",
    "    #     def fcn(yr):\n",
    "    #         return load(self.fetch(f'blkgrps_{yr}', url=f'https://www2.census.gov/geo/tiger/TIGER{yr}/BG/tl_{yr}_{self.state.fips}_bg.zip', unzip=False))\n",
    "    #     return self.run_years('blkgrps', fcn)\n",
    "\n",
    "    def get_vtds(self):\n",
    "        return self.get('vtds', url=f'https://data.capitol.texas.gov/dataset/4d8298d0-d176-4c19-b174-42837027b73e/resource/906f47e4-4e39-4156-b1bd-4969be0b2780/download/vtds_{self.current}pg.zip')\n",
    "\n",
    "    def get_tarrant(self):\n",
    "        return self.get('tarrant', coerce=True)\n",
    "\n",
    "    def get_pieces(self):\n",
    "        def fcn():\n",
    "            L = [[suf(yr), B.filter(['geoid','geometry']).rename(columns={'geoid':suf(yr)})] for yr, B in self.get_blkgrps()]\n",
    "            nm, df = L.pop()\n",
    "            print(nm)\n",
    "            while L:\n",
    "                nm, B = L.pop()\n",
    "                print(nm)\n",
    "                df = df.overlay(B)\n",
    "            print('vtds')\n",
    "            df = df.overlay(self.get_vtds().filter(['vtdkey','geometry']))\n",
    "            print('tarrant')\n",
    "            df = df.refine(self.get_tarrant().filter(['precinct','geometry']))\n",
    "            return df.get_area().query('area>1').simplify().buffer()\n",
    "        return self.get('pieces', fcn, prereq=[self.get_blkgrps, self.get_vtds, self.get_tarrant])\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Redistricting(Data):\n",
    "    acs_dict: dict = tuple()\n",
    "    districts: tuple = tuple()\n",
    "    offices: tuple = ('president','u.s. sen','governor','lt. governor','attorney gen')\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.acs_dict = {'B01003_001E':'pop_total'} | dict(self.acs_dict)\n",
    "        self.districts = [suf(yr) for yr in self.years] + ['vtdkey','county',*self.districts]\n",
    "\n",
    "    def get_votes(self):\n",
    "        def fcn():\n",
    "            return (\n",
    "                self.get_elections()\n",
    "                .query(f'office in {self.offices} and year in {self.years} and party in [\"d\",\"r\"]')\n",
    "                .assign(candidate=lambda X: X['office']+'_'+X['name']+'_'+X['party']+'_'+X['year'].astype('string'))\n",
    "                .pivot_table(index=['vtdkey','county'], columns='candidate', values='votes', fill_value=0)\n",
    "                .rename_axis(columns=None).reset_index()\n",
    "                )\n",
    "        return self.get('votes', fcn, prereq=[self.get_elections])\n",
    "\n",
    "    def get_cvap(self):\n",
    "        def fcn(yr):\n",
    "            src = self.fetch(f'cvap_{yr}', url=f'https://www2.census.gov/programs-surveys/decennial/rdo/datasets/{yr}/{yr}-cvap/CVAP_{yr-4}-{yr}_ACS_csv_files.zip')\n",
    "            df = load(src.parent/'BlockGr.csv', encoding='latin1')\n",
    "            df[suf(yr)] = df['geoid'].str[-12:]\n",
    "            df = df.pivot_table(index=suf(yr), columns='lntitle', values=['cit_est','cvap_est'], fill_value=0)\n",
    "            df.columns = [suf(yr, k[:-3]+v) for k,v in df.columns]\n",
    "            return df.reset_index()\n",
    "        return self.run_years('cvap', fcn)\n",
    "\n",
    "    def get_acs(self):\n",
    "        def fcn(yr):\n",
    "            df = pd.DataFrame(census.Census(self.api_key).acs5.state_county_blockgroup([*self.acs_dict.keys()], self.state.fips, '*', '*', year=yr))\n",
    "            g = lambda s, x: x.astype(str).str.rjust(s,'0')\n",
    "            df[suf(yr)] = g(2,df['state']) + g(3,df['county']) + g(6,df['tract']) + g(1,df['block group'])\n",
    "            return df[[suf(yr), *self.acs_dict.keys()]].rename(columns={k:suf(yr,v) for k,v in self.acs_dict.items()})\n",
    "        return self.run_years('acs', fcn)\n",
    "\n",
    "    def merge(self, other):\n",
    "        if 'merged' not in self:\n",
    "            self.merged = other\n",
    "        else:\n",
    "            try:\n",
    "                self.merged = self.merged.merge(other, how='left')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        # print(self.merged.columns)\n",
    "\n",
    "    def get_merged(self):\n",
    "        def fcn():\n",
    "            self.merge(self.get_pieces())\n",
    "            self.merge(self.get_tarrant().filter({*self.districts}.difference({'county'})))\n",
    "            self.merge(self.get_votes())\n",
    "            ACS = self.get_acs()\n",
    "            CVAP = self.get_cvap()\n",
    "            while ACS:\n",
    "                yr, A = ACS.pop()\n",
    "                yr, C = CVAP.pop()\n",
    "                self.merge(A)\n",
    "                self.merge(C)\n",
    "                pop  = suf(yr, 'pop_total')\n",
    "                cvap = suf(yr, 'cvap_total')\n",
    "                # {multiplier: {geoid: columns to scale by multiplier value in piece / multiplier value in geoid (aka: sum multiplier value over all pieces in geoid)}}\n",
    "                # area must be first to scale pop & cvap BEFORE using them to scale others\n",
    "                dct = {\n",
    "                    'area': {suf(yr): [pop, cvap ]},\n",
    "                    pop   : {suf(yr): [*A.columns[1:]]},\n",
    "                    cvap  : {suf(yr): [*C.columns[1:]] , 'vtdkey': [*self.get_votes().filter(like=str(yr)).columns]},\n",
    "                }\n",
    "                for mlt, d in dct.items():\n",
    "                    for geo, cols in d.items():\n",
    "                        self.merged[cols] *= self.merged.get_proportion(geo, mlt)\n",
    "            return self.merged\n",
    "        return self.get('merged', fcn, prereq=[self.get_pieces, self.get_tarrant, self.get_votes, self.get_acs, self.get_cvap])\n",
    "    \n",
    "    def get_dissolved(self, by='vtdkey'):\n",
    "        # combine pieces based on \"by\"\n",
    "        def fcn():\n",
    "            M = self.get_merged()\n",
    "            p = M.filter(like='pop_total').columns.max()\n",
    "            df = M[[by,'geometry']].dissolve(by).get_area()\n",
    "            for k in self.districts:\n",
    "                if k in M and k != by:\n",
    "                    df = df.join(M.groupby([by,k])[p].sum().sort_values().reset_index().groupby(by).last()[k])\n",
    "            df = df.join(M[M.columns.difference(df.columns)].groupby(by).sum())\n",
    "            return df\n",
    "        return self.get(f'dissolved_{by}', fcn, prereq=[self.get_merged])\n",
    "\n",
    "\n",
    "years = list(range(2014,2024))[::-1]\n",
    "self = Redistricting(\n",
    "    years=years,\n",
    "    districts = ['precinct','congress','senate','house','commish','jp','education'], \n",
    "    acs_dict = {\n",
    "        'B01003_001E': 'pop_total',\n",
    "    },\n",
    "    offices = [\n",
    "        'president','us sen','governor','lt governor','attorney gen',\n",
    "        # 'comptroller','land comm','ag comm',\n",
    "        # 'rr comm 1','rr comm 2','rr comm 3',\n",
    "        # 'sup ct chief','sup ct 1','sup ct 2','sup ct 3','sup ct 4','sup ct 5','sup ct 6','sup ct 7','sup ct 8','sup ct 9',\n",
    "        # 'cca pres judge','cca1','cca2','cca3','cca4','cca5','cca6','cca7','cca8','cca9',\n",
    "    ],\n",
    "    overwrite=set({\n",
    "        # 'elections'\n",
    "        # 'vtds',\n",
    "        # 'tarrant',\n",
    "\n",
    "        'blkgrps',\n",
    "        'pieces',\n",
    "        'votes',\n",
    "        'cvap',\n",
    "        'acs',\n",
    "        'merged',\n",
    "        'dissolved_vtdkey',\n",
    "        'dissolved_blkgrp',\n",
    "    }),\n",
    ")\n",
    "\n",
    "# self.get_blkgrps()\n",
    "# self.get_acs()\n",
    "# self.get_cvap()\n",
    "# self.get_pieces()\n",
    "self.get_dissolved('vtdkey')\n",
    "# self.get_dissolved('blkgrp_2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84c5d17b-3fe0-4830-bafa-e88e2eea28d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "self.get_pieces()['area'].mean()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "redistricting_wrangler",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
